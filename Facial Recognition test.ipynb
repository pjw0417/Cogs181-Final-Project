{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "525ad91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b984f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_olivetti_faces(shuffle=True, random_state=0)\n",
    "images = data.images.reshape((-1, 1, 64, 64)).astype(np.float32)  # Reshape to [N, C, H, W]\n",
    "targets = data.target\n",
    "\n",
    "# Split the dataset into training and testing\n",
    "train_images, test_images = images[:300], images[300:]\n",
    "train_targets, test_targets = targets[:300], targets[300:]\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "train_images_tensor = torch.tensor(train_images)\n",
    "train_targets_tensor = torch.tensor(train_targets)\n",
    "test_images_tensor = torch.tensor(test_images)\n",
    "test_targets_tensor = torch.tensor(test_targets)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(train_images_tensor, train_targets_tensor)\n",
    "test_dataset = TensorDataset(test_images_tensor, test_targets_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c9ada98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, activation_fn=nn.ReLU, drop_rate=0.0):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.activation_fn = activation_fn(inplace=True)\n",
    "        self.dropout = nn.Dropout(p=drop_rate)  # Dropout layer\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.activation_fn(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)  # Apply dropout\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.activation_fn(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=40, activation_fn=nn.ReLU):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        # Initial convolution\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.activation_fn = activation_fn(inplace=True)\n",
    "        \n",
    "        # ResNet layers\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1, activation_fn=activation_fn,drop_rate=0.1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2, activation_fn=activation_fn,drop_rate=0.1)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2, activation_fn=activation_fn,drop_rate=0.1)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2, activation_fn=activation_fn,drop_rate=0.1)\n",
    "\n",
    "        self._to_linear = None\n",
    "        self._get_conv_output_size(torch.rand(1, 1, 64, 64))\n",
    "\n",
    "        self.linear = nn.Linear(self._to_linear, num_classes)\n",
    "    \n",
    "    def _make_layer(self, block, planes, num_blocks, stride, activation_fn, drop_rate=0.0):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, activation_fn=activation_fn, drop_rate=drop_rate))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def _get_conv_output_size(self, shape):\n",
    "        with torch.no_grad():\n",
    "            self.eval()\n",
    "            output = self._forward_conv_only(shape)\n",
    "            self._to_linear = np.prod(output.size()[1:])\n",
    "            self.train()\n",
    "\n",
    "    def _forward_conv_only(self, x):\n",
    "        out = self.activation_fn(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self._forward_conv_only(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b18aa07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "num_blocks = [2, 2, 2, 2]  # ResNet18-like architecture\n",
    "model = ResNet(BasicBlock, num_blocks, num_classes=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ad46349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Loss: 0.0098, Train Accuracy: 99.67%\n",
      "Test Accuracy: 80.00%\n",
      "\n",
      "Epoch 2/40, Loss: 0.0381, Train Accuracy: 99.33%\n",
      "Test Accuracy: 57.00%\n",
      "\n",
      "Epoch 3/40, Loss: 0.0413, Train Accuracy: 99.00%\n",
      "Test Accuracy: 62.00%\n",
      "\n",
      "Epoch 4/40, Loss: 0.0121, Train Accuracy: 100.00%\n",
      "Test Accuracy: 78.00%\n",
      "\n",
      "Epoch 5/40, Loss: 0.0185, Train Accuracy: 99.67%\n",
      "Test Accuracy: 84.00%\n",
      "\n",
      "Epoch 6/40, Loss: 0.0040, Train Accuracy: 100.00%\n",
      "Test Accuracy: 84.00%\n",
      "\n",
      "Epoch 7/40, Loss: 0.0105, Train Accuracy: 99.67%\n",
      "Test Accuracy: 87.00%\n",
      "\n",
      "Epoch 8/40, Loss: 0.0670, Train Accuracy: 98.67%\n",
      "Test Accuracy: 80.00%\n",
      "\n",
      "Epoch 9/40, Loss: 0.0267, Train Accuracy: 98.67%\n",
      "Test Accuracy: 65.00%\n",
      "\n",
      "Epoch 10/40, Loss: 0.0398, Train Accuracy: 98.67%\n",
      "Test Accuracy: 33.00%\n",
      "\n",
      "Epoch 11/40, Loss: 0.0180, Train Accuracy: 99.33%\n",
      "Test Accuracy: 40.00%\n",
      "\n",
      "Epoch 12/40, Loss: 0.0216, Train Accuracy: 99.33%\n",
      "Test Accuracy: 52.00%\n",
      "\n",
      "Epoch 13/40, Loss: 0.0119, Train Accuracy: 99.33%\n",
      "Test Accuracy: 69.00%\n",
      "\n",
      "Epoch 14/40, Loss: 0.0345, Train Accuracy: 99.00%\n",
      "Test Accuracy: 74.00%\n",
      "\n",
      "Epoch 15/40, Loss: 0.0254, Train Accuracy: 99.33%\n",
      "Test Accuracy: 78.00%\n",
      "\n",
      "Epoch 16/40, Loss: 0.0038, Train Accuracy: 100.00%\n",
      "Test Accuracy: 68.00%\n",
      "\n",
      "Epoch 17/40, Loss: 0.0122, Train Accuracy: 99.67%\n",
      "Test Accuracy: 80.00%\n",
      "\n",
      "Epoch 18/40, Loss: 0.0024, Train Accuracy: 100.00%\n",
      "Test Accuracy: 80.00%\n",
      "\n",
      "Epoch 19/40, Loss: 0.0188, Train Accuracy: 99.67%\n",
      "Test Accuracy: 86.00%\n",
      "\n",
      "Epoch 20/40, Loss: 0.0146, Train Accuracy: 99.67%\n",
      "Test Accuracy: 84.00%\n",
      "\n",
      "Epoch 21/40, Loss: 0.0039, Train Accuracy: 100.00%\n",
      "Test Accuracy: 88.00%\n",
      "\n",
      "Epoch 22/40, Loss: 0.0024, Train Accuracy: 100.00%\n",
      "Test Accuracy: 91.00%\n",
      "\n",
      "Epoch 23/40, Loss: 0.0106, Train Accuracy: 99.67%\n",
      "Test Accuracy: 91.00%\n",
      "\n",
      "Epoch 24/40, Loss: 0.0020, Train Accuracy: 100.00%\n",
      "Test Accuracy: 87.00%\n",
      "\n",
      "Epoch 25/40, Loss: 0.0035, Train Accuracy: 100.00%\n",
      "Test Accuracy: 85.00%\n",
      "\n",
      "Epoch 26/40, Loss: 0.0026, Train Accuracy: 100.00%\n",
      "Test Accuracy: 87.00%\n",
      "\n",
      "Epoch 27/40, Loss: 0.0004, Train Accuracy: 100.00%\n",
      "Test Accuracy: 86.00%\n",
      "\n",
      "Epoch 28/40, Loss: 0.0003, Train Accuracy: 100.00%\n",
      "Test Accuracy: 86.00%\n",
      "\n",
      "Epoch 29/40, Loss: 0.0006, Train Accuracy: 100.00%\n",
      "Test Accuracy: 89.00%\n",
      "\n",
      "Epoch 30/40, Loss: 0.0002, Train Accuracy: 100.00%\n",
      "Test Accuracy: 91.00%\n",
      "\n",
      "Epoch 31/40, Loss: 0.0004, Train Accuracy: 100.00%\n",
      "Test Accuracy: 92.00%\n",
      "\n",
      "Epoch 32/40, Loss: 0.0002, Train Accuracy: 100.00%\n",
      "Test Accuracy: 93.00%\n",
      "\n",
      "Epoch 33/40, Loss: 0.0001, Train Accuracy: 100.00%\n",
      "Test Accuracy: 93.00%\n",
      "\n",
      "Epoch 34/40, Loss: 0.0002, Train Accuracy: 100.00%\n",
      "Test Accuracy: 93.00%\n",
      "\n",
      "Epoch 35/40, Loss: 0.0001, Train Accuracy: 100.00%\n",
      "Test Accuracy: 93.00%\n",
      "\n",
      "Epoch 36/40, Loss: 0.0001, Train Accuracy: 100.00%\n",
      "Test Accuracy: 94.00%\n",
      "\n",
      "Epoch 37/40, Loss: 0.0001, Train Accuracy: 100.00%\n",
      "Test Accuracy: 94.00%\n",
      "\n",
      "Epoch 38/40, Loss: 0.0002, Train Accuracy: 100.00%\n",
      "Test Accuracy: 94.00%\n",
      "\n",
      "Epoch 39/40, Loss: 0.0000, Train Accuracy: 100.00%\n",
      "Test Accuracy: 94.00%\n",
      "\n",
      "Epoch 40/40, Loss: 0.0001, Train Accuracy: 100.00%\n",
      "Test Accuracy: 94.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, '\n",
    "              f'Train Accuracy: {train_accuracy:.2f}%')\n",
    "        \n",
    "        # Evaluation phase\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "        \n",
    "        test_accuracy = 100 * correct_test / total_test\n",
    "        print(f'Test Accuracy: {test_accuracy:.2f}%\\n')\n",
    "\n",
    "\n",
    "# Now you can call the training function with the necessary parameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b333099a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (activation_fn): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation_fn): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation_fn): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation_fn): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation_fn): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation_fn): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation_fn): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation_fn): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation_fn): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=2048, out_features=40, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c5042d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 94.00%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # Disable gradient tracking\n",
    "    for images, labels in test_loader:  # Assuming test_loader is your test dataset DataLoader\n",
    "        images, labels = images.to(device), labels.to(device)  # Move to the correct device\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Get the index of the max log-probability\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc39b601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
